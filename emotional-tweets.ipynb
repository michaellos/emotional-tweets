{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/googles-trained-word2vec-model-in-python/GoogleNews-vectors-negative300.bin.gz\n",
      "/kaggle/input/googles-trained-word2vec-model-in-python/GoogleNews-vectors-negative300.bin\n",
      "/kaggle/input/emotional-tweets/sample_submission.csv\n",
      "/kaggle/input/emotional-tweets/test.csv\n",
      "/kaggle/input/emotional-tweets/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/emotional-tweets/train.csv', skiprows=[5930]) # incorrect row\n",
    "test = pd.read_csv('../input/emotional-tweets/test.csv',  dtype={'Id': object, 'Tweet': object})\n",
    "\n",
    "test = test.iloc[:4000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Id  Category  \\\n",
      "0  635769805279248384  negative   \n",
      "1  635930169241374720   neutral   \n",
      "2  635950258682523648   neutral   \n",
      "3  636030803433009153  negative   \n",
      "4  636100906224848896  positive   \n",
      "\n",
      "                                               Tweet  \n",
      "0                                      Not Available  \n",
      "1  IOS 9 App Transport Security. Mm need to check...  \n",
      "2  Mar if you have an iOS device, you should down...  \n",
      "3  @jimmie_vanagon my phone does not run on lates...  \n",
      "4  Not sure how to start your publication on iOS?...  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Id                                              Tweet\n",
      "0  628949369883000832  dear @Microsoft the newOoffice for Mac is grea...\n",
      "1  628976607420645377  @Microsoft how about you make a system that do...\n",
      "2  629023169169518592                                      Not Available\n",
      "3  629179223232479232                                      Not Available\n",
      "4  629186282179153920  If I make a game as a #windows10 Universal App...\n"
     ]
    }
   ],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging, re, nltk\n",
    "import pandas as pd\n",
    "import smart_open, os\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"../input/googles-trained-word2vec-model-in-python//GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.layer_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, review) for review in text_list ])\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8a60574ef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "train.Category.value_counts().plot(kind=\"bar\", rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "train_data, test_data = train_test_split(train, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = test_data.apply(lambda r: w2v_tokenize_text(r['Tweet']), axis=1).values\n",
    "train_tokenized = train_data.apply(lambda r: w2v_tokenize_text(r['Tweet']), axis=1).values\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "\n",
    "logreg = logreg.fit(X_train_word_average, train_data['Category'])\n",
    "predicted = logreg.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trafność klasyfikacji 0.5829145728643216\n",
      "Macierz pomyłek\n",
      " [[ 56  73  49]\n",
      " [ 50 185 205]\n",
      " [ 17 104 455]]\n"
     ]
    }
   ],
   "source": [
    "print('Trafność klasyfikacji %s' % accuracy_score(test_data.Category, predicted))\n",
    "cm = confusion_matrix(test_data.Category, predicted)\n",
    "print('Macierz pomyłek\\n %s' % cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost = XGBClassifier(n_estimators=1000, n_jobs=-1, learning_rate=0.05, random_state=21)\n",
    "xgboost.fit(X_train_word_average, train_data['Category'], verbose=False)\n",
    "predicted = xgboost.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trafność klasyfikacji 0.5720268006700168\n",
      "Macierz pomyłek\n",
      " [[ 41  85  52]\n",
      " [ 41 202 197]\n",
      " [ 12 124 440]]\n"
     ]
    }
   ],
   "source": [
    "print('Trafność klasyfikacji %s' % accuracy_score(test_data.Category, predicted))\n",
    "cm = confusion_matrix(test_data.Category, predicted)\n",
    "print('Macierz pomyłek\\n %s' % cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomForest = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=21)\n",
    "randomForest.fit(X_train_word_average, train_data['Category'])\n",
    "predicted = randomForest.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trafność klasyfikacji 0.567001675041876\n",
      "Macierz pomyłek\n",
      " [[  3 103  72]\n",
      " [  2 187 251]\n",
      " [  1  88 487]]\n"
     ]
    }
   ],
   "source": [
    "print('Trafność klasyfikacji %s' % accuracy_score(test_data.Category, predicted))\n",
    "cm = confusion_matrix(test_data.Category, predicted)\n",
    "print('Macierz pomyłek\\n %s' % cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['Tweet']), axis=1).values\n",
    "# X_train_word_average = word_averaging_list(wv,train_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)\n",
    "# results = cross_val_score(logreg, X_train_word_average, train['Category'], cv=kfold)\n",
    "# print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# xgboost = XGBClassifier(n_estimators=1000, n_jobs=-1, learning_rate=0.05, random_state=21)\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)\n",
    "# results = cross_val_score(xgboost, X_train_word_average, train['Category'], cv=kfold)\n",
    "# print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# randomForest = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=21)\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)\n",
    "# results = cross_val_score(randomForest, X_train_word_average, train['Category'], cv=kfold)\n",
    "# print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=1, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['Tweet']), axis=1).values\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "                                           \n",
    "best_model = LogisticRegression(n_jobs=1, C=1e5)\n",
    "best_model.fit(X_train_word_average, train['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = best_model\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['Tweet']), axis=1).values\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
    "\n",
    "preds_test = final_model.predict(X_test_word_average)\n",
    "\n",
    "output = pd.DataFrame({'Id': test.iloc[:, 0],\n",
    "                       'Category': preds_test})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
